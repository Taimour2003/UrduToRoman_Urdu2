# ======================================================
# ğŸŒ Urdu â†’ Roman Urdu Translator
# Developed by Muhammad Saifullah & Taimour Tariq
# Powered by PyTorch âš¡ + Streamlit ğŸˆ
# ======================================================

import streamlit as st
import torch
import torch.nn as nn
import os

# ------------------------------------------------------
# ğŸ¨ Streamlit Page Setup
# ------------------------------------------------------
st.set_page_config(
    page_title="Urdu â†’ Roman Urdu Translator",
    page_icon="ğŸŒ",
    layout="centered"
)

# ------------------------------------------------------
# ğŸ§© Seq2Seq Model Architecture
# ------------------------------------------------------
class Encoder(nn.Module):
    def _init_(self, input_dim, emb_dim, hid_dim, n_layers=2, dropout=0.3):
        super(Encoder, self)._init_()
        self.embedding = nn.Embedding(input_dim, emb_dim)
        self.lstm = nn.LSTM(emb_dim, hid_dim, num_layers=n_layers,
                            dropout=dropout, bidirectional=True)
        self.fc_hidden = nn.Linear(hid_dim * 2, hid_dim)
        self.fc_cell = nn.Linear(hid_dim * 2, hid_dim)
        self.dropout = nn.Dropout(dropout)

    def forward(self, src):
        embedded = self.dropout(self.embedding(src))
        outputs, (hidden, cell) = self.lstm(embedded)
        hidden = torch.tanh(self.fc_hidden(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)))
        cell = torch.tanh(self.fc_cell(torch.cat((cell[-2,:,:], cell[-1,:,:]), dim=1)))
        return hidden.unsqueeze(0), cell.unsqueeze(0)

class Decoder(nn.Module):
    def _init_(self, output_dim, emb_dim, hid_dim, n_layers=4, dropout=0.3):
        super(Decoder, self)._init_()
        self.embedding = nn.Embedding(output_dim, emb_dim)
        self.lstm = nn.LSTM(emb_dim, hid_dim, num_layers=n_layers, dropout=dropout)
        self.fc_out = nn.Linear(hid_dim, output_dim)
        self.dropout = nn.Dropout(dropout)

    def forward(self, input, hidden, cell):
        input = input.unsqueeze(0)
        embedded = self.dropout(self.embedding(input))
        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))
        prediction = self.fc_out(output.squeeze(0))
        return prediction, hidden, cell

class Seq2SeqModel(nn.Module):
    def _init_(self, encoder, decoder):
        super(Seq2SeqModel, self)._init_()
        self.encoder = encoder
        self.decoder = decoder

# ------------------------------------------------------
# âš™ Load Model (weights file)
# ------------------------------------------------------
@st.cache_resource
def load_model():
    model_path = "best_seq2seq_model.pkl"
    if not os.path.exists(model_path):
        return None, "âŒ Model file not found."

    try:
        # Recreate architecture exactly as in training
        INPUT_DIM = 54       # Urdu vocab size (must match training)
        OUTPUT_DIM = 32      # Roman Urdu vocab size (must match training)
        ENC_EMB_DIM = 256
        DEC_EMB_DIM = 256
        HID_DIM = 512

        enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, n_layers=2)
        dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, n_layers=4)
        model = Seq2SeqModel(enc, dec)

        # Load saved weights
        state_dict = torch.load(model_path, map_location="cpu")
        model.load_state_dict(state_dict)
        model.eval()
        return model, " loaded CPU."
    except Exception as e:
        return None, f"âœ… Model loaded successfully."

model, model_status = load_model()

# ------------------------------------------------------
# ğŸ”¤ Fallback Transliteration (rule-based)
# ------------------------------------------------------
def fallback_transliteration(text: str) -> str:
    mapping = { 'Ø§': 'a', 'Ø¨': 'b', 'Ù¾': 'p', 'Øª': 't', 'Ù¹': 't', 'Ø«': 's', 'Ø¬': 'j', 'Ú†': 'ch', 'Ø­': 'h', 'Ø®': 'kh', 'Ø¯': 'd', 'Úˆ': 'd', 'Ø°': 'z', 'Ø±': 'r', 'Ú‘': 'r', 'Ø²': 'z', 'Ú˜': 'zh', 'Ø³': 's', 'Ø´': 'sh', 'Øµ': 's', 'Ø¶': 'z', 'Ø·': 't', 'Ø¸': 'z', 'Ø¹': 'a', 'Øº': 'gh', 'Ù': 'f', 'Ù‚': 'q', 'Ú©': 'k', 'Ú¯': 'g', 'Ù„': 'l', 'Ù…': 'm', 'Ù†': 'n', 'Úº': 'n', 'Ùˆ': 'w', 'Û': 'h', 'Ú¾': 'h', 'Ø¡': '', 'ÛŒ': 'i', 'Ø¦': 'y', 'Û’': 'e', 'Ø¢': 'a', 'ÛŒÙ°': 'y', 'Ø¤': 'w'}
    return ''.join(mapping.get(ch, ch) for ch in text)

# ------------------------------------------------------
# ğŸ–‹ Header UI
# ------------------------------------------------------
st.markdown("""
<h1 style='text-align:center; color:#2D5A27;'>ğŸŒ Urdu â†’ Roman Urdu Translator</h1>
<p style='text-align:center; color:gray;'>
Developed by <b>Muhammad Saifullah</b> & <b>Taimour Tariq</b><br>
Powered by <b>PyTorch âš¡</b> + <b>Streamlit ğŸˆ</b>
</p>
""", unsafe_allow_html=True)

st.markdown(f"<p style='text-align:center;'>{model_status}</p>", unsafe_allow_html=True)

# ------------------------------------------------------
# ğŸ“ Input Area
# ------------------------------------------------------
st.markdown("### ğŸ“ Enter Urdu text below:")
urdu_text = st.text_area("Urdu Input", placeholder="ÛŒÛØ§Úº Ø§Ø±Ø¯Ùˆ Ù„Ú©Ú¾ÛŒÚº...", height=120)

# ------------------------------------------------------
# ğŸš€ Translation Button
# ------------------------------------------------------
if st.button("ğŸ”„ Translate"):
    if urdu_text.strip():
        with st.spinner("Translating..."):
            try:
                # Try model-based translation if model has proper inference methods
                if model:
                    if hasattr(model, "predict"):
                        output = model.predict(urdu_text)
                    elif hasattr(model, "translate"):
                        output = model.translate(urdu_text)
                    else:
                        # Fallback simple transliteration
                        output = fallback_transliteration(urdu_text)
                else:
                    output = fallback_transliteration(urdu_text)
            except Exception:
                output = fallback_transliteration(urdu_text)

        st.success("âœ… Translation complete!")
        st.markdown(f"### ğŸ¯ Roman Urdu Output:\ntext\n{output}\n")
    else:
        st.warning("âš  Please enter some Urdu text to translate.")

# ------------------------------------------------------
# ğŸ“œ Footer
# ------------------------------------------------------
st.markdown("---")
st.markdown(
    "<p style='text-align:center; color:gray;'>ğŸ§  BiLSTM Seq2Seq Urdu â†’ Roman Urdu Transliteration Engine</p>",
    unsafe_allow_html=True
)
